{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4769a76f-2b1d-485c-b152-81c323e3937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff305e70-d217-4ad5-81d6-2290c34a2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettifyDurationInSeconds(pDurationInSeconds):\n",
    "    seconds = pDurationInSeconds % 60\n",
    "    durationInMinutes = (pDurationInSeconds - seconds) // 60\n",
    "    minutes = durationInMinutes % 60\n",
    "    hours = (durationInMinutes - minutes) // 60\n",
    "\n",
    "    return f\"{hours}h {minutes}m {seconds}s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da60f1d2-d24c-4227-a0a1-afe8412fe773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arange(start, end, step):\n",
    "    return np.linspace(start, end, int(np.ceil((end - start) / step) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70439bac-b9bd-42ea-9331-d6cb1e03bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_threshold(a, b):\n",
    "    return np.sign(a) * np.maximum(np.abs(a) - b, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc472430-2f1a-4c62-a196-c837a7892101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(breakpoints, penalties, bias):\n",
    "    breakpoints = [float(\"-inf\")] + breakpoints + [float(\"+inf\")]\n",
    "    minus_sum = 0\n",
    "    plus_sum = sum(penalties)\n",
    "\n",
    "    for i in range(len(breakpoints) - 1):        \n",
    "        v = bias - minus_sum + plus_sum\n",
    "\n",
    "        if breakpoints[i] < v <= breakpoints[i + 1]:\n",
    "            return v\n",
    "\n",
    "        if i == len(breakpoints) - 2:\n",
    "            break\n",
    "\n",
    "        minus_sum += penalties[i]\n",
    "        plus_sum -= penalties[i]\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a815ff15-3b3b-4dab-9f39-ca26551495a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLSA_2D:\n",
    "    __slots__ = ['__lambda_1', '__lambda_2', '__max_iter', '__tol', 'n1', 'n2', 'G', 'neighbours', 'y_bar', 'N', 'gamma']\n",
    "    \n",
    "    @property\n",
    "    def coef_(self):\n",
    "        # initiate matrix of sizes of original data matrix y\n",
    "        r = np.zeros((self.n1, self.n2))\n",
    "        # iterate over every found group\n",
    "        for k in range(len(self.G)):\n",
    "            # iterate over every point that belongs to that group\n",
    "            for p in self.G[k]:\n",
    "                # set value of pixel at point p to value of gamma of that group\n",
    "                r[p[0], p[1]] = self.gamma[k]\n",
    "        # return result\n",
    "        return r\n",
    "        \n",
    "    def __init__(self, lambda_1=1.0, lambda_2=1.0, max_iter=1000, tol=0.0001):\n",
    "        self.__lambda_1 = lambda_1\n",
    "        self.__lambda_2 = lambda_2\n",
    "        self.__max_iter = max_iter\n",
    "        self.__tol = tol\n",
    "        \n",
    "        return\n",
    "\n",
    "    def loss(self, gamma):\n",
    "        s = 0\n",
    "        for k in range(len(gamma)):\n",
    "            s += (np.array(list(self.neighbours[k].values())) * abs(gamma[k] - gamma[list(self.neighbours[k].keys())])).sum()\n",
    "                    \n",
    "        return 0.5 * (self.N * (self.y_bar - gamma) ** 2).sum() + self.__lambda_1 * (self.N * abs(gamma)).sum() + self.__lambda_2 / 2 * s\n",
    "\n",
    "    def roughly_equal(self, a, b):\n",
    "        return np.linalg.norm(a - b, 2) < self.__tol\n",
    "\n",
    "    def fit(self, y, quick=True):\n",
    "        # set increment for lambda_2\n",
    "        delta = 1e-9\n",
    "        # read shape of incoming data\n",
    "        self.n1, self.n2 = y.shape\n",
    "        # function to check whether point p=(i, j) is in bounds of data matrix y\n",
    "        def in_bounds(i, j):\n",
    "            return 0 <= i < self.n1 and 0 <= j < self.n2\n",
    "        # initiate set of groups — every pixel is its own group at the beginning\n",
    "        self.G = [[(i, j)] for i in range(self.n1) for j in range(self.n2)]\n",
    "        # set of neighbours\n",
    "        # self.neighbours[k] is a dict of neighbours of k-th group \n",
    "        # where keys correspond to indexes of groups of these neighbours\n",
    "        # and values to length of shared border between group k and this neighbour\n",
    "        # at the beginning every pixel has either 2, 3 or 4 neighbours\n",
    "        self.neighbours = []\n",
    "        for i in range(self.n1):\n",
    "            for j in range(self.n2):\n",
    "                # initiate list of neighbours\n",
    "                self.neighbours.append({})\n",
    "                # if there is neighbour above\n",
    "                if in_bounds(i - 1, j):\n",
    "                    # add it with shared border length 1\n",
    "                    self.neighbours[-1][(i - 1) * self.n1 + j] = 1\n",
    "                # if there is neighbour below\n",
    "                if in_bounds(i + 1, j):\n",
    "                    # add it with shared border length 1\n",
    "                    self.neighbours[-1][(i + 1) * self.n1 + j] = 1\n",
    "                # if there is neighbour to the left\n",
    "                if in_bounds(i, j - 1):\n",
    "                    # add it with shared border length 1\n",
    "                    self.neighbours[-1][i * self.n1 + j - 1] = 1\n",
    "                # if there is neighbour to the right\n",
    "                if in_bounds(i, j + 1):\n",
    "                    # add it with shared border length 1\n",
    "                    self.neighbours[-1][i * self.n1 + j + 1] = 1\n",
    "        # average value of data at every group\n",
    "        # since every group as of now consists of only one pixel it has exactly data matrix y values\n",
    "        self.y_bar = y.flatten()\n",
    "        # sizes of groups, i.e. 1 for every group\n",
    "        self.N = np.ones(y.shape, dtype=np.int32).flatten()\n",
    "        # initial values of gamma\n",
    "        gamma = soft_threshold(self.y_bar, self.__lambda_1)\n",
    "        # smooth cycle\n",
    "        # for quicker computations there is available option of using static number of iterations — 1000\n",
    "        # if to be precies as in paper, second option allows to increment values from 0 to lambda_2 by ~delta\n",
    "        for lambda_2 in (np.linspace(delta, self.__lambda_2, 10) if quick else arange(delta, self.__lambda_2, delta)):\n",
    "            # retry cycles until converged\n",
    "            converged = False\n",
    "            for _ in range(self.__max_iter):\n",
    "                # copy current value of gamma so to compare if there was an successful update\n",
    "                current_gamma = gamma.copy()\n",
    "                # iterate over every coordinate\n",
    "                for k in range(len(self.G)):\n",
    "                    # descent part — try to minimise only in gamma[k] direction\n",
    "                    # derivative is piece-wise linear at breakpoints\n",
    "                    breakpoints = np.concatenate(([0], gamma[list(self.neighbours[k].keys())]))\n",
    "                    # with scaling parameters stored in penalties\n",
    "                    penalties = np.concatenate(([self.__lambda_1], lambda_2 * np.array(list(self.neighbours[k].values())) / self.N[k]))\n",
    "                    # we need to sort by breakpoints\n",
    "                    s = np.argsort(breakpoints)\n",
    "                    breakpoints = breakpoints[s]\n",
    "                    penalties = penalties[s]\n",
    "                    # and since it is piece-wise linear, solution is unique if exists\n",
    "                    r = solve(breakpoints.tolist(), penalties.tolist(), self.y_bar[k])\n",
    "                    # copy current value of gamma to compare if update with found solution for gamma[k] is better than before\n",
    "                    gamma_tmp = gamma.copy()\n",
    "                    # if there is no solution (0 falls in one of the breaks)\n",
    "                    if r is None:                        \n",
    "                        min_v = float(\"+inf\")\n",
    "                        # we check what value gives loss function with gamma[k] set to breakpoint\n",
    "                        # and select such value that gives the smallest value of loss\n",
    "                        for _breakpoint in breakpoints:\n",
    "                            gamma_tmp[k] = _breakpoint\n",
    "                            # evaluate\n",
    "                            v = self.loss(gamma_tmp)\n",
    "                            if v < min_v:\n",
    "                                min_v = v\n",
    "                                r = _breakpoint\n",
    "                    # so we substitute to check if such an update is good\n",
    "                    gamma_tmp[k] = r\n",
    "                    # if it is better\n",
    "                    if self.loss(gamma_tmp) < self.loss(gamma):\n",
    "                        # then use this value\n",
    "                        gamma = gamma_tmp\n",
    "                        # and continue to the next coordinate\n",
    "                        continue\n",
    "                    # if there was no successful one-parameter-at-a-time update we consider fusion part\n",
    "                    # iterate over every neighbouring group of k-th group and consider fusion\n",
    "                    for k_prime in self.neighbours[k].keys():\n",
    "                        # simulate size of potential group\n",
    "                        N_m = self.N[k] + self.N[k_prime]\n",
    "                        # simulate average data value at potential group\n",
    "                        y_bar_m = (self.N[k] * self.y_bar[k] + self.N[k_prime] * self.y_bar[k_prime]) / N_m\n",
    "                        # evaluate neighbours of potential group\n",
    "                        neighbours_m = {idx: (0 if not idx in self.neighbours[k].keys() else self.neighbours[k][idx]) + (0 if not idx in self.neighbours[k_prime].keys() else self.neighbours[k_prime][idx]) for idx in set(list(self.neighbours[k].keys()) + list(self.neighbours[k_prime].keys())) if idx != k and idx != k_prime}\n",
    "                        # apply descent at the direction of fused coordinate\n",
    "                        # derivative is piece-wise linear at breakpoints\n",
    "                        breakpoints = np.concatenate(([0], gamma[list(neighbours_m.keys())]))\n",
    "                        # with scaling parameters stored in penalties\n",
    "                        penalties = np.concatenate(([self.__lambda_1], lambda_2 * np.array(list(neighbours_m.values())) / N_m))\n",
    "                        # we need to sort by breakpoints\n",
    "                        s = np.argsort(breakpoints)\n",
    "                        breakpoints = breakpoints[s]\n",
    "                        penalties = penalties[s]\n",
    "                        # and since it is piece-wise linear, solution is unique if exists\n",
    "                        r = solve(breakpoints.tolist(), penalties.tolist(), y_bar_m)\n",
    "                        # copy current value of gamma to compare if update with found solution for gamma[k] is better than before                    \n",
    "                        gamma_tmp = gamma.copy()\n",
    "                        # if there is no solution (0 falls in one of the breaks)\n",
    "                        if r is None:\n",
    "                            min_v = float(\"+inf\")\n",
    "                            # we check what value gives loss function with gamma[k] and gamma[k_prime] set to breakpoint\n",
    "                            # and select such value that gives the smallest value of loss\n",
    "                            for _breakpoint in breakpoints:\n",
    "                                gamma_tmp[k] = _breakpoint\n",
    "                                gamma_tmp[k_prime] = _breakpoint\n",
    "                                # evaluate\n",
    "                                v = self.loss(gamma_tmp)\n",
    "                                if v < min_v:\n",
    "                                    min_v = v\n",
    "                                    r = _breakpoint\n",
    "                        # so we substitute to check if such an update is good\n",
    "                        gamma_tmp[k] = r\n",
    "                        gamma_tmp[k_prime] = r\n",
    "                        # if it is better\n",
    "                        if self.loss(gamma_tmp) < self.loss(gamma):\n",
    "                            # then use this value\n",
    "                            gamma = gamma_tmp\n",
    "                            # and continue to the next coordinate\n",
    "                            continue\n",
    "                # when previous value of gammma is not substantially different from newly acquired one\n",
    "                if np.linalg.norm(current_gamma - gamma, 2) < self.__tol:\n",
    "                    # then we found solution for given lambda_2\n",
    "                    converged = True\n",
    "                    break\n",
    "            # show log, if algorithm did not converge\n",
    "            if not converged:\n",
    "                print(\"algorithm did not converge\")\n",
    "            # now time to fuse groups close to each other\n",
    "            k = 0\n",
    "            # iterate over every group\n",
    "            while k < len(self.G):\n",
    "                # get indexes of neighbours of current k-th group\n",
    "                neighbours_k_indexes = self.neighbours[k].keys()\n",
    "                # store indexes of neighbours which are to be fused\n",
    "                indexes_of_groups_to_fuse = []\n",
    "                # iterate over every neighbour\n",
    "                for k_prime in neighbours_k_indexes:\n",
    "                    # if calculated values of gamma for group k and respective neighbour are close enough and non-zero\n",
    "                    if self.roughly_equal(gamma[[k]], gamma[[k_prime]]) and not self.roughly_equal(gamma[[k]], 0):\n",
    "                        # then we want to fuse these two together\n",
    "                        indexes_of_groups_to_fuse.append(k_prime)\n",
    "                        # we fuse neighbour into k-th group!\n",
    "                        # update groups — union of points\n",
    "                        self.G[k].extend(self.G[k_prime])\n",
    "                        # update sizes of groups\n",
    "                        self.N[k] += self.N[k_prime]\n",
    "                        # update average values of data of groups\n",
    "                        self.y_bar[k] = (self.y_bar[k] * (self.N[k] - self.N[k_prime]) + self.y_bar[k_prime] * self.N[k_prime]) / self.N[k]\n",
    "                        # recalculate neighbours for new group:\n",
    "                        # iterate over union of neighbours of k-th group and neighbour-to-be-fused group excluding these groups themselves\n",
    "                        # calculate new shared borders lengths\n",
    "                        self.neighbours[k] = {idx: (0 if idx not in self.neighbours[k].keys() else self.neighbours[k][idx]) + (0 if idx not in self.neighbours[k_prime].keys() else self.neighbours[k_prime][idx]) for idx in set(list(self.neighbours[k].keys()) + list(self.neighbours[k_prime].keys())) if idx != k and idx != k_prime}\n",
    "                        # update such values for neighbours too\n",
    "                        for key, value in self.neighbours[k].items():\n",
    "                            # remove the neighbouring relationship with group-to-be-fused since it will get deleted\n",
    "                            if k_prime in self.neighbours[key].keys():\n",
    "                                del self.neighbours[key][k_prime]\n",
    "                            # update shared border length on the new neighbour side\n",
    "                            self.neighbours[key][k] = value\n",
    "                # help function to calculate how indexes shift when items are deleted\n",
    "                def _help(key, remo):\n",
    "                    i = 0\n",
    "                    for el in remo:\n",
    "                        if key > el:\n",
    "                            i += 1\n",
    "                    return key - i\n",
    "                # since we delete some groups their indexes in self.G get shifted (example: deleting 7th group\n",
    "                # makes group with index 10 to now have index 9, but group with index 0 retains that value)\n",
    "                # here is the dictionary that maps old indexes to new ones. Why? Because even though we delete entries in self.neighbours\n",
    "                # and self.G other entries in self.neighbours are still relying on old indexes, so we need to update that values.\n",
    "                # we use that map-dictionary to do that.\n",
    "                _map = {key: _help(key, indexes_of_groups_to_fuse) for key in range(len(self.G)) if key not in indexes_of_groups_to_fuse}\n",
    "                # remove fused groups\n",
    "                self.G = [el for i, el in enumerate(self.G) if i not in indexes_of_groups_to_fuse]\n",
    "                # remove sizes of fused groups\n",
    "                self.N = np.delete(self.N, indexes_of_groups_to_fuse)\n",
    "                # remove average data values of fused groups\n",
    "                self.y_bar = np.delete(self.y_bar, indexes_of_groups_to_fuse)\n",
    "                # update referencing indexes and remove neighbouring sets of fused groups\n",
    "                self.neighbours = [{_map[item]: value for item, value in el.items()} for i, el in enumerate(self.neighbours) if i not in indexes_of_groups_to_fuse]\n",
    "                # remove gamma values of fused groups\n",
    "                gamma = np.delete(gamma, indexes_of_groups_to_fuse)\n",
    "                # continue to the next unfused group\n",
    "                k += 1\n",
    "        # save found gamma value\n",
    "        self.gamma = gamma.copy()\n",
    "        # return estimator\n",
    "        return self"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32da60e1-655f-464d-8ff6-febdc19638c0",
   "metadata": {},
   "source": [
    "o_dim = 3\n",
    "scale = 4\n",
    "\n",
    "y_original = np.random.binomial(1, 0.3, o_dim * o_dim).reshape(o_dim, o_dim) * np.random.uniform(0, 1, (o_dim, o_dim)).round(2)\n",
    "y_original = y_original.repeat(scale, axis=0).repeat(scale, axis=1)\n",
    "y = y_original + np.random.normal(0, 0.1, y_original.shape)\n",
    "\n",
    "pd.DataFrame(y_original).to_csv(\"y_original.csv\", header=False, index=False)\n",
    "pd.DataFrame(y).to_csv(\"y.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc382261-2a91-42d2-8ae5-e34d87630b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"c/data/y.csv\", header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789c03da-ae91-48aa-a683-f13365586668",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = FLSA_2D(lambda_1=0.12, lambda_2=0.15).fit(y)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1fe4aa-9dfe-4c11-810b-2322895b2ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation took 6.0h 13.0m 45.633788108825684s\n"
     ]
    }
   ],
   "source": [
    "print(f\"evaluation took {prettifyDurationInSeconds(end - start)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "084cb7aa-be60-4af4-a8b2-3c406c0f0470",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "ax[0].matshow(y_original)\n",
    "ax[0].set_title(\"y original\")\n",
    "ax[1].matshow(y)\n",
    "ax[1].set_title(\"y noised\")\n",
    "ax[2].matshow(model.coef_)\n",
    "ax[2].set_title(\"denoised y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213bb859-8398-4c01-903b-4b53c742430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.coef_).to_csv(\"c/data/gamma_python.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b0bf84d-a3dc-4073-97b0-caeecfe5fdbb",
   "metadata": {},
   "source": [
    "04x04 evaluation took 0.0h 0.0m 0.9637553691864014s (evaluation took 0h 0m 0s)\n",
    "09x09 evaluation took 0.0h 0.0m 58.88158178329468s (evaluation took 0h 0m 2s)\n",
    "16x16 evaluation took 0.0h 11.0m 11.560818672180176s (evaluation took 0h 0m 28s)\n",
    "32x32 evaluation took 6.0h 13.0m 45.633788108825684s (evaluation took 0h 10m 16s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
